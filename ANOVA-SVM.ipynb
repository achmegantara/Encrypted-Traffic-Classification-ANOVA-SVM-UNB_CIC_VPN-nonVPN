{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "##Klasifikasi\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#wrapper method\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#METHOD EVALUATION\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6667, 23)\n",
      "(2858, 23)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#create names of the feature\n",
    "col_names = [\"duration\",\"total_fiat\",\"total_biat\",\"min_fiat\",\"min_biat\",\"max_fiat\",\"max_biat\",\"mean_fiat\",\"mean_biat\",\"flowPktsPerSecond\",\"flowBytesPerSecond\",\"min_flowiat\",\"max_flowiat\",\"mean_flowiat\",\"std_flowiat\",\"min_active\",\"mean_active\",\"max_active\",\"std_active\",\"min_idle\",\"mean_idle\",\"max_idle\",\"std_idle\"]\n",
    "\n",
    "#import dataset\n",
    "df = pd.read_csv('dataset/scenarioA1/TimeBasedFeatures-Dataset-120s-VPN.csv')\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "\n",
    "#separate dataset with label\n",
    "dfX = df.drop('class1',1)\n",
    "dfY = df.class1\n",
    "\n",
    "#scenario1\n",
    "dfY = dfY.replace({'Non-VPN' : 1, 'VPN' : 2})\n",
    "\n",
    "#scenario2\n",
    "#dfY = dfY.replace({'BROWSING' : 1, 'P2P' : 2, 'FT' : 3, 'MAIL' : 4, 'VOIP' : 5, 'CHAT' : 6, 'STREAMING' : 7, 'VPN-BROWSING' : 8, 'VPN-P2P' : 9, 'VPN-FT' : 10, 'VPN-MAIL' : 11, 'VPN-VOIP' : 12, 'VPN-CHAT' : 13, 'VPN-STREAMING' : 14})\n",
    "\n",
    "#scenario3\n",
    "#dfY = dfY.replace({'BROWSING' : 1, 'P2P' : 2, 'FT' : 3, 'MAIL' : 4, 'VOIP' : 5, 'CHAT' : 6, 'STREAMING' : 7})\n",
    "\n",
    "#Split data training & data testing\n",
    "X_train_filter, X_test_filter, Y_train, Y_test = train_test_split(dfX, dfY, test_size=0.3, random_state=42)\n",
    "\n",
    "#list column names\n",
    "colNames=list(X_train_filter)\n",
    "colNames_test=list(X_test_filter)\n",
    "\n",
    "constant_filter = VarianceThreshold(threshold=0.01)\n",
    "constant_filter.fit(X_train_filter)\n",
    "X_train = constant_filter.transform(X_train_filter)\n",
    "X_test = constant_filter.transform(X_test_filter)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#Data normalization\n",
    "scaler1 = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler1.transform(X_train)\n",
    "scaler2 = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test = scaler2.transform(X_test)\n",
    "\n",
    "#cek the standard deviation\n",
    "print(X_train.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance SVM : \n",
      "fiture ke- 1 = -0.30431566027885654\n",
      "fiture ke- 2 = -0.375466086971976\n",
      "fiture ke- 3 = -0.007035399253907069\n",
      "fiture ke- 4 = -0.006953808699762736\n",
      "fiture ke- 5 = -0.007050174901425893\n",
      "fiture ke- 6 = -0.007039412548139572\n",
      "fiture ke- 7 = -0.006845322310228013\n",
      "fiture ke- 8 = -0.006866791904650011\n",
      "fiture ke- 9 = -0.006920968047559849\n",
      "fiture ke- 10 = -0.006786795202921477\n",
      "fiture ke- 11 = -0.0066089922119646205\n",
      "fiture ke- 12 = -0.006658284241172336\n",
      "fiture ke- 13 = -0.006862080916721545\n",
      "fiture ke- 14 = -0.005747943779591142\n",
      "fiture ke- 15 = -0.00589476488224471\n",
      "fiture ke- 16 = -0.006057862908480393\n",
      "fiture ke- 17 = -0.006070024930342694\n",
      "fiture ke- 18 = -0.0060051176460516435\n",
      "fiture ke- 19 = -0.004992775702792706\n",
      "fiture ke- 20 = -0.005266406296603902\n",
      "fiture ke- 21 = -0.005287237694501054\n",
      "fiture ke- 22 = -0.0054471029395996495\n",
      "fiture ke- 23 = -0.005257881210563212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "anova_filter = SelectKBest(f_regression)\n",
    "clf2 = LinearSVC()\n",
    "anova_svm = Pipeline([('anova', anova_filter), ('linearSVC', clf2)])\n",
    "\n",
    "anova_svm_scores = list()\n",
    "acc_scores = list()\n",
    "distance = list()\n",
    "\n",
    "for k in range(1,24,1):\n",
    "    anova_svm.set_params(anova__k=k).fit(X_train, Y_train)\n",
    "    y = anova_svm.decision_function(X_train)\n",
    "    coef = anova_svm[:-1].inverse_transform(anova_svm['linearSVC'].coef_)\n",
    "    w_norm = np.linalg.norm(coef)\n",
    "    dist = y / w_norm\n",
    "    dist_mean = np.mean(dist)\n",
    "    distance.append(dist_mean)\n",
    "#     prediction = anova_svm.predict(X_train)\n",
    "#     sc = anova_svm.score(X_train,Y_train)\n",
    "#     pred = anova_svm.predict(X_test)\n",
    "#     acc = accuracy_score(Y_test, pred)\n",
    "#     anova_svm_scores.append(sc)\n",
    "#     acc_scores.append(acc)\n",
    "\n",
    "print(\"Distance SVM : \")\n",
    "for a in range(0,23,1):\n",
    "    print(\"fiture ke-\",a+1,\"=\",distance[a])\n",
    "\n",
    "# print(\"Anova-SVM Scores : \")\n",
    "# for a in range(0,23,1):\n",
    "#     print(\"fitur ke-\",a+1,\"=\",anova_svm_scores[a])\n",
    "# print(\"Accuracy Scores : \")\n",
    "# for b in range(0,23,1):\n",
    "#     print(\"fitur ke-\",b+1,\"=\",acc_scores[b])\n",
    "    \n",
    "#anova_svm.named_steps['anova'].get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x218f41964c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xCor = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "plt.scatter(xCor, distance, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "-0.03527986502087203\n",
      "value\n",
      "-0.30431566027885654\n",
      "-0.375466086971976\n",
      "-0.007035399253907069\n",
      "-0.006953808699762736\n",
      "-0.007050174901425893\n",
      "-0.007039412548139572\n",
      "-0.006845322310228013\n",
      "-0.006866791904650011\n",
      "-0.006920968047559849\n",
      "-0.006786795202921477\n",
      "-0.0066089922119646205\n",
      "-0.006658284241172336\n",
      "-0.006862080916721545\n",
      "-0.005747943779591142\n",
      "-0.00589476488224471\n",
      "-0.006057862908480393\n",
      "-0.006070024930342694\n",
      "-0.0060051176460516435\n",
      "-0.004992775702792706\n",
      "-0.005266406296603902\n",
      "-0.005287237694501054\n",
      "-0.0054471029395996495\n",
      "-0.005257881210563212\n"
     ]
    }
   ],
   "source": [
    "sel_features = []\n",
    "thres = np.mean(distance)\n",
    "for x in range(0,23,1):\n",
    "    if distance[x] > thres:\n",
    "        sel_features.append(True)\n",
    "    elif distance[x] < thres:\n",
    "        sel_features.append(False)\n",
    "print(sel_features)\n",
    "print(thres)\n",
    "print(\"value\")\n",
    "for y in distance:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004992775702792706\n",
      "-0.375466086971976\n",
      "-0.03527986502087203\n"
     ]
    }
   ],
   "source": [
    "print(max(distance))\n",
    "print(min(distance))\n",
    "print(np.mean(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "['total_biat', 'min_fiat', 'min_biat', 'max_fiat', 'max_biat', 'mean_fiat', 'mean_biat', 'flowPktsPerSecond', 'flowBytesPerSecond', 'min_flowiat', 'max_flowiat', 'mean_flowiat', 'std_flowiat', 'min_active', 'mean_active', 'max_active', 'std_active', 'min_idle', 'mean_idle', 'max_idle', 'std_idle']\n"
     ]
    }
   ],
   "source": [
    "colNum = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "true = sel_features\n",
    "colindex = [i for i, x in enumerate(true) if x]\n",
    "colNumber = list(colNum[i] for i in colindex)\n",
    "print(colNumber)\n",
    "\n",
    "colindex2 = [i for i, x in enumerate(true) if x]\n",
    "colName = list(colNames[i] for i in colindex)\n",
    "print(colName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6667, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(X_train)\n",
    "X_train_new = temp[colNumber]\n",
    "X_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all features\n",
    "#create classifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "lgr = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nvb = GaussianNB()\n",
    "\n",
    "#Fit the model\n",
    "clf.fit(X_train, Y_train)\n",
    "rfc.fit(X_train, Y_train)\n",
    "lgr.fit(X_train, Y_train)\n",
    "svm.fit(X_train, Y_train)\n",
    "knn.fit(X_train, Y_train)\n",
    "nvb.fit(X_train, Y_train)\n",
    "\n",
    "#create predicted data\n",
    "clf_predict = clf.predict(X_test)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "lgr_predict = lgr.predict(X_test)\n",
    "svm_predict = svm.predict(X_test)\n",
    "knn_predict = knn.predict(X_test)\n",
    "nvb_predict = nvb.predict(X_test)\n",
    "\n",
    "#--------------------------------------------------------------------#\n",
    "\n",
    "#Selected features\n",
    "#reduce features in test dataset\n",
    "#create classifier\n",
    "X_test_new = X_test[:,colindex]\n",
    "clf_sel = DecisionTreeClassifier(random_state=0)\n",
    "rfc_sel = RandomForestClassifier(random_state=0)\n",
    "lgr_sel = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "svm_sel = SVC()\n",
    "knn_sel = KNeighborsClassifier()\n",
    "nvb_sel = GaussianNB()\n",
    "\n",
    "#fit the model\n",
    "clf_sel.fit(X_train_new, Y_train)\n",
    "rfc_sel.fit(X_train_new, Y_train)\n",
    "lgr_sel.fit(X_train_new, Y_train)\n",
    "svm_sel.fit(X_train_new, Y_train)\n",
    "knn_sel.fit(X_train_new, Y_train)\n",
    "nvb_sel.fit(X_train_new, Y_train)\n",
    "\n",
    "#create predicted data\n",
    "clf_predict_sel = clf_sel.predict(X_test_new)\n",
    "rfc_predict_sel = rfc_sel.predict(X_test_new)\n",
    "lgr_predict_sel = lgr_sel.predict(X_test_new)\n",
    "svm_predict_sel = svm_sel.predict(X_test_new)\n",
    "knn_predict_sel = knn_sel.predict(X_test_new)\n",
    "nvb_predict_sel = nvb_sel.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of all features : \n",
      "Accuracy of Decision Tree =   0.5010496850944717\n",
      "Accuracy of Random Forest =   0.5850244926522044\n",
      "Accuracy of Logistic Regression =   0.5542337298810357\n",
      "Accuracy of SVM =   0.6186144156752974\n",
      "Accuracy of KNN =   0.6504548635409377\n",
      "Accuracy of Naive Bayes =   0.4793561931420574\n",
      "\n",
      "Performance of selected features : \n",
      "Accuracy of Decision Tree =   0.5538838348495452\n",
      "Accuracy of Random Forest =   0.5937718684394682\n",
      "Accuracy of Logistic Regression =   0.5545836249125262\n",
      "Accuracy of SVM =   0.6004198740377886\n",
      "Accuracy of KNN =   0.6763470958712386\n",
      "Accuracy of Naive Bayes =   0.480405878236529\n",
      "\n",
      "Accuracy: 0.81070 (+/- 0.05124)\n",
      "Accuracy: 0.86214 (+/- 0.03527)\n",
      "Accuracy: 0.54514 (+/- 0.05122)\n",
      "Accuracy: 0.58818 (+/- 0.05102)\n",
      "Accuracy: 0.76278 (+/- 0.04818)\n",
      "Accuracy: 0.48252 (+/- 0.04330)\n"
     ]
    }
   ],
   "source": [
    "# cm = confusion_matrix(Y_test_all, Y_all_pred)\n",
    "# print(pd.crosstab(Y_test_all, Y_all_pred, rownames=['Actual activity'], colnames=['Predicted activity']))\n",
    "# # print(classification_report(Y_test, Y_all_pred))\n",
    "# TP = cm[1][1]\n",
    "# FN = cm[1][0]\n",
    "# FP = cm[0][1]\n",
    "# TN = cm[0][0]\n",
    "# accuracy_all = (TP+TN)/(TP+TN+FP+FN)\n",
    "# sensitivity_all = TP/(TP+FN)\n",
    "# specificity_all = TN/(TN+FP)\n",
    "# false_alarm_all = FP/(FP+TN)\n",
    "\n",
    "#Accuracy\n",
    "#all features\n",
    "print(\"Performance of all features : \")\n",
    "print(\"Accuracy of Decision Tree =  \", accuracy_score(Y_test, clf_predict))\n",
    "print(\"Accuracy of Random Forest =  \", accuracy_score(Y_test, rfc_predict))\n",
    "print(\"Accuracy of Logistic Regression =  \", accuracy_score(Y_test, lgr_predict))\n",
    "print(\"Accuracy of SVM =  \", accuracy_score(Y_test, svm_predict))\n",
    "print(\"Accuracy of KNN =  \", accuracy_score(Y_test, knn_predict))\n",
    "print(\"Accuracy of Naive Bayes =  \", accuracy_score(Y_test, nvb_predict))\n",
    "print()\n",
    "\n",
    "#selected features\n",
    "print(\"Performance of selected features : \")\n",
    "print(\"Accuracy of Decision Tree =  \", accuracy_score(Y_test, clf_predict_sel))\n",
    "print(\"Accuracy of Random Forest =  \", accuracy_score(Y_test, rfc_predict_sel))\n",
    "print(\"Accuracy of Logistic Regression =  \", accuracy_score(Y_test, lgr_predict_sel))\n",
    "print(\"Accuracy of SVM =  \", accuracy_score(Y_test, svm_predict_sel))\n",
    "print(\"Accuracy of KNN =  \", accuracy_score(Y_test, knn_predict_sel))\n",
    "print(\"Accuracy of Naive Bayes =  \", accuracy_score(Y_test, nvb_predict_sel))\n",
    "print()\n",
    "\n",
    "#selected with cross-validation\n",
    "accuracy = cross_val_score(clf_sel, X_test_new, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "accuracy = cross_val_score(rfc_sel, X_test_new, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "accuracy = cross_val_score(lgr_sel, X_test_new, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "accuracy = cross_val_score(svm_sel, X_test_new, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "accuracy = cross_val_score(knn_sel, X_test_new, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "accuracy = cross_val_score(nvb_sel, X_test_new, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPUTATION TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start1 = time.time()\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "clf_predict = clf.predict(X_test)\n",
    "time1 = (time.time()-start1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start2 = time.time()\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(X_train, Y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "time2 = (time.time()-start2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start3 = time.time()\n",
    "lgr = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "lgr.fit(X_train, Y_train)\n",
    "lgr_predict = lgr.predict(X_test)\n",
    "time3 = (time.time()-start3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start4 = time.time()\n",
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "svm_predict = svm.predict(X_test)\n",
    "time4 = (time.time()-start4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start5 = time.time()\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "knn_predict = knn.predict(X_test)\n",
    "time5 = (time.time()-start5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start6 = time.time()\n",
    "nvb = GaussianNB()\n",
    "nvb.fit(X_train, Y_train)\n",
    "nvb_predict = nvb.predict(X_test)\n",
    "time6 = (time.time()-start6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20586943626403809\n",
      "2.1302003860473633\n",
      "0.22985529899597168\n",
      "3.988807439804077\n",
      "0.5232176780700684\n",
      "0.013994216918945312\n"
     ]
    }
   ],
   "source": [
    "print(time1)\n",
    "print(time2)\n",
    "print(time3)\n",
    "print(time4)\n",
    "print(time5)\n",
    "print(time6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = X_test[:,colindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start7 = time.time()\n",
    "clf_sel = DecisionTreeClassifier(random_state=0)\n",
    "clf_sel.fit(X_train_new, Y_train)\n",
    "clf_predict_sel = clf_sel.predict(X_test_new)\n",
    "time7 = (time.time()-start7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start8 = time.time()\n",
    "rfc_sel = RandomForestClassifier(random_state=0)\n",
    "rfc_sel.fit(X_train_new, Y_train)\n",
    "rfc_predict_sel = rfc_sel.predict(X_test_new)\n",
    "time8 = (time.time()-start8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start9  = time.time()\n",
    "lgr_sel = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "lgr_sel.fit(X_train_new, Y_train)\n",
    "lgr_predict_sel = lgr_sel.predict(X_test_new)\n",
    "time9 = (time.time()-start9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start10 = time.time()\n",
    "svm_sel = SVC()\n",
    "svm_sel.fit(X_train_new, Y_train)\n",
    "svm_predict_sel = svm_sel.predict(X_test_new)\n",
    "time10 = (time.time()-start10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start11 = time.time()\n",
    "knn_sel = KNeighborsClassifier()\n",
    "knn_sel.fit(X_train_new, Y_train)\n",
    "knn_predict_sel = knn_sel.predict(X_test_new)\n",
    "time11 = (time.time()-start11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start12 = time.time()\n",
    "nvb_sel = GaussianNB()\n",
    "nvb_sel.fit(X_train_new, Y_train)\n",
    "nvb_predict_sel = nvb_sel.predict(X_test_new)\n",
    "time12 = (time.time()-start12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1669008731842041\n",
      "2.044292449951172\n",
      "0.2258608341217041\n",
      "3.831047534942627\n",
      "0.8958945274353027\n",
      "0.015991926193237305\n"
     ]
    }
   ],
   "source": [
    "print(time7)\n",
    "print(time8)\n",
    "print(time9)\n",
    "print(time10)\n",
    "print(time11)\n",
    "print(time12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_feat = 9\n",
    "# anova_fil = SelectKBest(f_regression)\n",
    "# clf = SVC()\n",
    "# anova_svm_sel = Pipeline([('anova', anova_fil), ('SVC',clf)])\n",
    "\n",
    "# anova_svm_sel.set_params(anova__k=n_feat).fit(X_train, Y_train)\n",
    "# prediction2 = anova_svm_sel.predict(X_train)\n",
    "# anova_svm_sel.score(X_train, Y_train)\n",
    "\n",
    "# anova_svm_sel.named_steps['anova'].get_support()\n",
    "# colNum = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "# true = anova_svm_sel.named_steps['anova'].get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_filter = SelectKBest(f_regression)\n",
    "# clf2 = SVC(kernel='linear')\n",
    "# anova_svm = Pipeline([('anova', anova_filter), ('SVC', clf2)])\n",
    "# num_k = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "\n",
    "# anova_svm_scores = list()\n",
    "# acc_scores = list()\n",
    "\n",
    "# for k in num_k:\n",
    "#     anova_svm.set_params(anova__k=k).fit(X_train, Y_train)\n",
    "#     #anova-SVM scores\n",
    "#     anova_svm_scores_pred = anova_svm.predict(X_train)\n",
    "#     sc = anova_svm_scores_pred.score(X_train,Y_train)\n",
    "#     anova_svm_scores.append(sc)\n",
    "#     #accuracy scores\n",
    "#     acc_pred = anova_svm.predict(X_test)\n",
    "#     acc = accuracy_score(Y_test, acc_pred)\n",
    "#     acc_scores.append(acc)\n",
    "\n",
    "# print(\"Anova-SVM Scores : \")\n",
    "# print(anova_svm_scores)\n",
    "# print(\"Accuracy Scores : \")\n",
    "# print(acc)s\n",
    "# print(anova_svm.named_steps['anova'].get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform2 = SelectKBest(f_regression)\n",
    "# clf2 = Pipeline([('anova', transform2), ('svc', SVC(C=0.1))])\n",
    "\n",
    "# score_means2 = list()\n",
    "# score_stds2 = list()\n",
    "# k = (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23)\n",
    "\n",
    "# for percentile in k:\n",
    "#     clf2.set_params(anova__k=percentile)\n",
    "#     this_scores = cross_val_score(clf2, X_train, Y_train, n_jobs=1)\n",
    "#     score_means2.append(this_scores.mean())\n",
    "#     score_stds2.append(this_scores.std())\n",
    "    \n",
    "# plt.errorbar(k, score_means2, np.array(score_stds2))\n",
    "\n",
    "# plt.title('Performance of the SVM-ANOVA varying the percentile of features selected')\n",
    "# plt.xlabel('Percentile')\n",
    "# plt.ylabel('Prediction rate')\n",
    "\n",
    "# plt.axis('tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = SelectPercentile(f_classif)\n",
    "# clf = Pipeline([('anova', transform), ('svc', SVC(C=1.0))])\n",
    "\n",
    "# score_means = list()\n",
    "# score_stds = list()\n",
    "# percentiles = (1,3,6,10,15,20,30,40,60,80,100)\n",
    "\n",
    "# for percentile in percentiles:\n",
    "#     clf.set_params(anova__percentile=percentile)\n",
    "#     this_scores = cross_val_score(clf, X_train, Y_train, cv=10, n_jobs=1)\n",
    "#     score_means.append(this_scores.mean())\n",
    "#     score_stds.append(this_scores.std())\n",
    "    \n",
    "# plt.errorbar(percentiles, score_means, np.array(score_stds))\n",
    "\n",
    "# plt.title('Performance of the SVM-ANOVA varying the percentile of features selected')\n",
    "# plt.xlabel('Percentile')\n",
    "# plt.ylabel('Prediction rate')\n",
    "\n",
    "# plt.axis('tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.7 (default, Apr 15 2020, 05:09:04) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
